{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\thali\\anaconda3\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\thali\\anaconda3\\lib\\site-packages (from openai) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thali\\anaconda3\\lib\\site-packages (from openai) (4.50.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from aiohttp->openai) (5.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\thali\\anaconda3\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->openai) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import openai\n",
    "\n",
    "def get_keys():\n",
    "    key = csv.reader(open('openai_key.csv', 'r'), delimiter=',')\n",
    "\n",
    "    for row in key:\n",
    "        openai_key = row[0]\n",
    "\n",
    "    return openai_key\n",
    "\n",
    "openai.api_key = get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-6sbm6WMfwXdFLl6cJOCMCByELNSbx at 0x226bdd33400> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"\\n\\nO 2\\u00b0 Congresso.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1678472938,\n",
       "  \"id\": \"chatcmpl-6sbm6WMfwXdFLl6cJOCMCByELNSbx\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 9,\n",
       "    \"prompt_tokens\": 19,\n",
       "    \"total_tokens\": 28\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct =openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": \"corrija a frase: o 2? congresso\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_correct =openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": \"corrija apenas o caractere � e retorne apenas a frase corrijida: o 2� congresso\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o 2º congresso'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['choices'][0]['message']['content'].replace('\\n\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = 'corrija apenas o caractere � e retorne apenas a frase corrijida: ap�s a pris�o dos jovens, como se fosse a m�dia enumerando os acontecimentos   �poca.'\n",
    "\n",
    "text_correct =openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": incorrect_text}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Após a prisão dos jovens, como se fosse a mídia enumerando os acontecimentos época.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['choices'][0]['message']['content'].replace('\\n\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = 'corrija caractere � e retorne apenas a frase corrijida: uma pessoa estava andando pela rua e viu um cachorro � atravessando a rua.'\n",
    "\n",
    "text_correct =openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": incorrect_text}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uma pessoa estava andando pela rua e viu um cachorro atravessando a rua.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['choices'][0]['message']['content'].replace('\\n\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thali\\AppData\\Local\\Temp\\ipykernel_28516\\896843367.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('ambiguous_samples.csv', sep=\">sep>\", header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ambiguous_samples.csv', sep=\">sep>\", header=None)\n",
    "df.columns = ['date', 'newspaper', 'news_id', 'invalid_word', 'fix_sample', 'slice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'especial para a Folha Para quem não passou, o período p�s-vestibular � traumático. Todo mundo -todo o mundo mesmo- vem perguntar como � que foi, e a sua auto-estima'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['slice'][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste com 2 caracteres estranhos na mesma frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = 'o período p�s-vestibular � traumático'\n",
    "\n",
    "text_correct =openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"corrija o caractere � e retorne apenas a frase corrijida:{incorrect_text}\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1c81dc3f270> JSON: {\n",
       "  \"completion_tokens\": 15,\n",
       "  \"prompt_tokens\": 35,\n",
       "  \"total_tokens\": 50\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['usage']['total_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O período pós-vestibular é traumático.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['choices'][0]['message']['content'].replace('\\n\\n','') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = 'porque o Janj�o (não � lindo o nome dele?)'\n",
    "\n",
    "text_correct = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"corrija o caractere � e retorne apenas a frase corrijida:{incorrect_text}\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1c81dc3f2c0> JSON: {\n",
       "  \"completion_tokens\": 18,\n",
       "  \"prompt_tokens\": 41,\n",
       "  \"total_tokens\": 59\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Porque o Janjão (não é lindo o nome dele?)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['choices'][0]['message']['content'].replace('\\n\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = \" na base do `l� l� l� l� l�' mesmo, entre outras coisas\"\n",
    "\n",
    "text_correct = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"corrija o caractere � e retorne apenas a frase corrijida:{incorrect_text}\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1c81dc86450> JSON: {\n",
       "  \"completion_tokens\": 20,\n",
       "  \"prompt_tokens\": 45,\n",
       "  \"total_tokens\": 65\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'na base do \"lá lá lá lá lá\" mesmo, entre outras coisas.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['choices'][0]['message']['content'].replace('\\n\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = 'Não � � toa que ele'\n",
    "text_correct = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"corrija o caractere � e retorne apenas a frase corrijida:{incorrect_text}\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.openai_object.OpenAIObject"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1f3962ef040> JSON: {\n",
       "  \"completion_tokens\": 8,\n",
       "  \"prompt_tokens\": 31,\n",
       "  \"total_tokens\": 39\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Não é à toa que ele'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_correct['choices'][0]['message']['content'].replace('\\n\\n','')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de um dataset com noticias incorretas e corrijidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thali\\AppData\\Local\\Temp\\ipykernel_2028\\2777821513.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('ambiguous_samples.csv', sep=\">sep>\", header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ambiguous_samples.csv', sep=\">sep>\", header=None)\n",
    "df.columns = ['date', 'newspaper', 'news_id', 'invalid_word', 'fix_sample', 'slice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noticias = df[['news_id', 'fix_sample', 'slice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noticias_sample = df_noticias.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('noticias_sample.csv', 'w') as f:\n",
    "    df_noticias_sample.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_news = df_noticias_sample['slice'].tolist()\n",
    "len(incorrect_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "text_correct = []\n",
    "for _incorrect_news in incorrect_news:\n",
    "    time.sleep(10)\n",
    "    incorrect_text = _incorrect_news\n",
    "    text_correct.append(openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"corrija o caractere � e retorne apenas a frase corrijida:{incorrect_text}\"}\n",
    "        ]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivo com dados corrigidos\n",
    "import json \n",
    "with open('text_correct.json', 'w') as f:\n",
    "    json.dump(text_correct, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>usage</th>\n",
       "      <th>choices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatcmpl-6uPPhBBDDZPubiBllBocs6dnGh21X</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678902077</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 87, 'completion_tokens': 44,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatcmpl-6uPQ66ibPSMQfdHc3YqlaxeoWrZFK</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678902102</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 78, 'completion_tokens': 62,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatcmpl-6uPQSuw0ylz2pi7zW4cfZ5U2xir1i</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678902124</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 86, 'completion_tokens': 63,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatcmpl-6uPQsYUZcAgRzKU6VVuAgXi4x7bPB</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678902150</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 78, 'completion_tokens': 56,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatcmpl-6uPRCT2NmOxyGPEvRp5oBQnUSVTeU</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678902170</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 83, 'completion_tokens': 125...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>chatcmpl-6uPuFFug0IIFuLOWXwF8OPpq4fFCs</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678903971</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 73, 'completion_tokens': 52,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>chatcmpl-6uPubM6u6WTlaMjhRBeVqLUcDKrI5</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678903993</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 87, 'completion_tokens': 72,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>chatcmpl-6uPutZZ5Kj3AqesUIcMNQdLqiwgb2</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678904011</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 80, 'completion_tokens': 32,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>chatcmpl-6uPvCZDJ29OfFUu1Pky93KGzDjZua</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678904030</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 83, 'completion_tokens': 24,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>chatcmpl-6uPvXJYsgvfW3qdOfD4hqrj7JNlTA</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1678904051</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>{'prompt_tokens': 83, 'completion_tokens': 58,...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id           object     created  \\\n",
       "0   chatcmpl-6uPPhBBDDZPubiBllBocs6dnGh21X  chat.completion  1678902077   \n",
       "1   chatcmpl-6uPQ66ibPSMQfdHc3YqlaxeoWrZFK  chat.completion  1678902102   \n",
       "2   chatcmpl-6uPQSuw0ylz2pi7zW4cfZ5U2xir1i  chat.completion  1678902124   \n",
       "3   chatcmpl-6uPQsYUZcAgRzKU6VVuAgXi4x7bPB  chat.completion  1678902150   \n",
       "4   chatcmpl-6uPRCT2NmOxyGPEvRp5oBQnUSVTeU  chat.completion  1678902170   \n",
       "..                                     ...              ...         ...   \n",
       "95  chatcmpl-6uPuFFug0IIFuLOWXwF8OPpq4fFCs  chat.completion  1678903971   \n",
       "96  chatcmpl-6uPubM6u6WTlaMjhRBeVqLUcDKrI5  chat.completion  1678903993   \n",
       "97  chatcmpl-6uPutZZ5Kj3AqesUIcMNQdLqiwgb2  chat.completion  1678904011   \n",
       "98  chatcmpl-6uPvCZDJ29OfFUu1Pky93KGzDjZua  chat.completion  1678904030   \n",
       "99  chatcmpl-6uPvXJYsgvfW3qdOfD4hqrj7JNlTA  chat.completion  1678904051   \n",
       "\n",
       "                 model                                              usage  \\\n",
       "0   gpt-3.5-turbo-0301  {'prompt_tokens': 87, 'completion_tokens': 44,...   \n",
       "1   gpt-3.5-turbo-0301  {'prompt_tokens': 78, 'completion_tokens': 62,...   \n",
       "2   gpt-3.5-turbo-0301  {'prompt_tokens': 86, 'completion_tokens': 63,...   \n",
       "3   gpt-3.5-turbo-0301  {'prompt_tokens': 78, 'completion_tokens': 56,...   \n",
       "4   gpt-3.5-turbo-0301  {'prompt_tokens': 83, 'completion_tokens': 125...   \n",
       "..                 ...                                                ...   \n",
       "95  gpt-3.5-turbo-0301  {'prompt_tokens': 73, 'completion_tokens': 52,...   \n",
       "96  gpt-3.5-turbo-0301  {'prompt_tokens': 87, 'completion_tokens': 72,...   \n",
       "97  gpt-3.5-turbo-0301  {'prompt_tokens': 80, 'completion_tokens': 32,...   \n",
       "98  gpt-3.5-turbo-0301  {'prompt_tokens': 83, 'completion_tokens': 24,...   \n",
       "99  gpt-3.5-turbo-0301  {'prompt_tokens': 83, 'completion_tokens': 58,...   \n",
       "\n",
       "                                              choices  \n",
       "0   [{'message': {'role': 'assistant', 'content': ...  \n",
       "1   [{'message': {'role': 'assistant', 'content': ...  \n",
       "2   [{'message': {'role': 'assistant', 'content': ...  \n",
       "3   [{'message': {'role': 'assistant', 'content': ...  \n",
       "4   [{'message': {'role': 'assistant', 'content': ...  \n",
       "..                                                ...  \n",
       "95  [{'message': {'role': 'assistant', 'content': ...  \n",
       "96  [{'message': {'role': 'assistant', 'content': ...  \n",
       "97  [{'message': {'role': 'assistant', 'content': ...  \n",
       "98  [{'message': {'role': 'assistant', 'content': ...  \n",
       "99  [{'message': {'role': 'assistant', 'content': ...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noticias_corretas = pd.DataFrame(text_correct)\n",
    "df_noticias_corretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('noticias_corrigidas.csv', 'w') as f:\n",
    "    df_noticias_corretas.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i até cogitado como possível candidato ao governo de São Paulo, mas acabou desistindo e declarando apoio a Alckmin. O correto seria \"pré-campanha\".'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noticias_corretas['choices'][0][0]['message']['content'].replace('\\n\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14816"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantidade de tokens utilizados para corrigir as notícias\n",
    "tokens = 0\n",
    "for i in range(len(text_correct)):\n",
    "    tokens = tokens + text_correct[i]['usage']['total_tokens']\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_noticias_corretas['choices'][0][0]['message']['content'].replace('\\n\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22461"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade total de caracteres\n",
    "caracteres = 0\n",
    "for i in range(len(text_correct)):\n",
    "    caracteres = caracteres + len(df_noticias_corretas['choices'][i][0]['message']['content'].replace('\\n\\n',''))\n",
    "caracteres"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram utilizados 14816 tokens para corrigeção de 100 notícias incorretas\n",
    "\n",
    "cada notícia tem em média 200 caracteres <br>\n",
    "Total de 22461 caracteres de notícias corrigidas\n",
    "\n",
    "Custo:\n",
    "- 1000 tokens = $0.002 <br>\n",
    "- 14816 tokens = $0.029632\n",
    "\n",
    "- 100 noticias = $0.029632 <br>\n",
    "- 6000000 noticias = $177.792,00\n",
    "\n",
    "<br>\n",
    "Tempo total com sleep de 10 segundos a cada requisição\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
